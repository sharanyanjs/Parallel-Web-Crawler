# ğŸ•·ï¸ Parallel Web Crawler (Java)

A high-performance, multi-threaded web crawler built with Java (17+), demonstrating advanced concurrency patterns, functional programming, and performance profiling.

## ğŸ“‹ Table of Contents
- [âœ¨ Features](#-features)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ® How to Use](#-how-to-use)
- [ğŸ”§ Code Examples](#-code-examples)
- [ğŸ§ª Testing](#-testing)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

## âœ¨ Features

### ğŸ¯ Core Functionality
- **âœ… Parallel Crawling** â€“ Multi-threaded web page processing with `ForkJoinPool`
- **âœ… Performance Profiling** â€“ Method-level execution time tracking with `@Profiled` annotations
- **âœ… JSON Configuration** â€“ Flexible configuration via JSON files
- **âœ… Word Frequency Analysis** â€“ Count and rank most frequent words
- **âœ… URL Deduplication** â€“ Thread-safe visited URL tracking

### âš¡ Technical Highlights
- **ğŸ—ï¸ Concurrency Patterns** â€“ `RecursiveAction`, `ConcurrentHashMap`, `ConcurrentSkipListSet`
- **ğŸ”„ Functional Programming** â€“ Stream API for word counting without loops
- **ğŸ­ Design Patterns** â€“ Builder, Factory, Proxy, Dependency Injection
- **ğŸ“Š Dynamic Proxies** â€“ Non-invasive method interception for profiling
- **ğŸ¯ Dependency Injection** â€“ Guice for loose coupling and testability
- **ğŸ“¦ JSON Processing** â€“ Jackson library for configuration and output

### ğŸŒŸ Unique Enhancements
- **âš¡ Smart Parallelism** â€“ Auto-scales based on available CPU cores
- **â±ï¸ Deadline Management** â€“ Respects timeout constraints gracefully
- **ğŸ“ˆ Depth Limiting** â€“ Prevents infinite crawling with configurable depth
- **ğŸ”— Link Extraction** â€“ Recursive discovery of nested pages
- **ğŸ“ Profiling Output** â€“ Detailed method execution timing reports
- **ğŸ›¡ï¸ Error Resilience** â€“ Continues crawling despite individual page failures

## ğŸ—ï¸ Architecture

+--------------------+
|  WebCrawlerMain    |
+--------------------+
          |
          v
+--------------------+
| ConfigurationLoader|
+--------------------+
          |
          v
+--------------------+
| ParallelWebCrawler |
|  (ForkJoinPool)    |
+--------------------+
          |
          v
+--------------------+
| PageParserFactory  |
+--------------------+
          |
          v
+--------------------+
| Profiler (Proxy)   |
+--------------------+
          |
          v
+--------------------+
| CrawlResultWriter  |
+--------------------+


## ğŸš€ Quick Start

### Prerequisites
- â˜• **Java JDK 17+**
- ğŸ—ï¸ **Maven 3.6.3+**
- ğŸŒ **Internet connection** (for web crawling)
- ğŸ’» **IntelliJ IDEA** (recommended) or any Java IDE

### Installation
```bash
# 1. Clone the repository
git clone https://github.com/yourusername/parallel-web-crawler.git

# 2. Navigate to the project directory
cd parallel-web-crawler

# 3. Build the project
mvn clean package

# Run the sequential crawler (legacy implementation)
java -jar target/udacity-webcrawler-1.0.jar src/main/config/sample_config_sequential.json

# Run the parallel crawler (4 threads)
java -jar target/udacity-webcrawler-1.0.jar src/main/config/sample_config.json

### ğŸ® How to Use
ğŸ‘¤ Basic Usage Flow
âš™ï¸ Configure â€“ Edit JSON configuration file

ğŸš€ Run Crawler â€“ Execute with config file

ğŸ“Š View Results â€“ Check output JSON file

ğŸ“ˆ Analyze Performance â€“ Review profiling data
