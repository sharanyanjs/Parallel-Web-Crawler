# ðŸ•·ï¸ Parallel Web Crawler (Java)

A high-performance, multi-threaded web crawler built with Java (17+), demonstrating advanced concurrency patterns, functional programming, and performance profiling.

## ðŸ“‹ Table of Contents
- [âœ¨ Features](#-features)
- [ðŸ—ï¸ Architecture](#ï¸-architecture)
- [ðŸš€ Quick Start](#-quick-start)
- [ðŸ“ Project Structure](#-project-structure)
- [ðŸŽ® How to Use](#-how-to-use)
- [ðŸ”§ Code Examples](#-code-examples)
- [ðŸ§ª Testing](#-testing)
- [ðŸ¤ Contributing](#-contributing)
- [ðŸ“„ License](#-license)

## âœ¨ Features

### ðŸŽ¯ Core Functionality
- **âœ… Parallel Crawling** â€“ Multi-threaded web page processing with `ForkJoinPool`
- **âœ… Performance Profiling** â€“ Method-level execution time tracking with `@Profiled` annotations
- **âœ… JSON Configuration** â€“ Flexible configuration via JSON files
- **âœ… Word Frequency Analysis** â€“ Count and rank most frequent words
- **âœ… URL Deduplication** â€“ Thread-safe visited URL tracking

### âš¡ Technical Highlights
- **ðŸ—ï¸ Concurrency Patterns** â€“ `RecursiveAction`, `ConcurrentHashMap`, `ConcurrentSkipListSet`
- **ðŸ”„ Functional Programming** â€“ Stream API for word counting without loops
- **ðŸ­ Design Patterns** â€“ Builder, Factory, Proxy, Dependency Injection
- **ðŸ“Š Dynamic Proxies** â€“ Non-invasive method interception for profiling
- **ðŸŽ¯ Dependency Injection** â€“ Guice for loose coupling and testability
- **ðŸ“¦ JSON Processing** â€“ Jackson library for configuration and output

### ðŸŒŸ Unique Enhancements
- **âš¡ Smart Parallelism** â€“ Auto-scales based on available CPU cores
- **â±ï¸ Deadline Management** â€“ Respects timeout constraints gracefully
- **ðŸ“ˆ Depth Limiting** â€“ Prevents infinite crawling with configurable depth
- **ðŸ”— Link Extraction** â€“ Recursive discovery of nested pages
- **ðŸ“ Profiling Output** â€“ Detailed method execution timing reports
- **ðŸ›¡ï¸ Error Resilience** â€“ Continues crawling despite individual page failures

## ðŸ—ï¸ Architecture

flowchart TD
    A[WebCrawlerMain]
    
    A --> B[ConfigurationLoader]
    A --> C[CrawlResultWriter]
    A --> D[ParallelWebCrawler<br/>(ForkJoinPool)]
    
    D --> E[PageParserFactory]
    D --> F[Profiler<br/>(Dynamic Proxy)]
